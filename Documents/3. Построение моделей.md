# Подготовка моделей

## Общее описание

На основе подготовленного датасета была произведена подготовка моделей машинного обучения. 

Перед подготовкой данных были произведены стандартные операции по разделению признаков и прогнозируемой переменной, произведена нормализация признаков для устранения выбросов и приведения данных к общему виду. 

Были рассмотрены следующие модели. 
1. Линейная многофакторная регрессия для первичных экспериментов и оценки базовых параметров. 
2. Регуляризированные модели - для работы в условиях возможной мультиколлинеарности, и для работы по отбору признаков.
3. Деревья решениий - для анализа работы в условиях наличия  нелинейных зависимостей. 
4. Случайный лес - для задачи, если итоговый признаки будут иметь сложную взаимосвязь. 
5. Градиентный  бустинг - как один из самых мощных методов машинного обучения. 

Также было протестировано применение ансамблиевых методов регрессии - Stacking и Voting регрессоров. 

## Общий алгоритм

Для более оптимального построения моделей создадим несколько функций. 
- функция загрузки данных в модель машинного обучения и вывод основных метрик. 
- проверка модели на уровень переобучениия. 
Данные функции были объединены в одну функцию для организации более полного отчета о работе модели. 

Далее данная функция была вызвана для каждой из моделей.

Итоговый вывод функции содержал данные о метриках модели - RMSE, MAE, R^2, а также выводил результаты, склонная ли модели к переобучению или нет. 

## Общий результат

Лучше всего для нашего кейса подходят модели стандартной регрессии и модели Lasso и Ridge с регуляризацией. Несмотря на то, что модель градиентного бустинга и также показала хороший результат, уровень склонности к переобучению у нее несколько выше, чем у моделей выше. 

Модели, основанные на дереве решений, было решено не использовать из-за высокого уровня переобучения. 

После построения моделей было решено протестировать возможность использования ансамблиевых методов.

Результаты Stacking-ансамля показали лучшие результаты по метрикам (по коэффициенту детерминации, например). Поэтому в итоге можно сказать, что лучше всего для решения задачи нам будут подходить следующие модели:

1. Модель линейной регрессии (с учетом того, что в датасете необходимо работать над решение проблемы мультиколлинеарности факторов). 
2. Модели Lasso и Ridge, так как они лучше всего работаю в условиях, когда данные имеют очень тесные связи. 
3. Stacking-ансамли, которые включают модели линейной регрессии и и модели с регуляризацией. 

Все модели подошли под требования к метрикам качества, которые были выделены в рамках этапа по постановке задачи:
- Модель должна предсказывать коэффициент Гармонии с точностью не хуже 95%. 
- RMSE меньше или равно 0.02.
- MAE меньше или равно 0,01.
- Коэффициент  детерминации должен быть равен 0.95 или более.

Модели также строятся и сохраняются скриптом "Model save.py". Готовые модели доступны в директории Models.